{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='all'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find out outlier data by field\n",
    "\n",
    "# Iterate over features and create box plots\n",
    "# for feature in FeatureFieldN + NumberFields:\n",
    "for feature in [\"Age\"]:\n",
    "    print(feature)\n",
    "    df_orig[[feature]].boxplot()\n",
    "    plt.title(f'Distribution of {feature} Features')\n",
    "    plt.ylabel('Values')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show all fields correlation\n",
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='viridis', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find out if it is possible to group loan application to approve/reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use unsuperivised kmeans method to group data\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# to extract features\n",
    "df_train = df[FeatureFieldNH + FeatureFieldOH + FeatureFieldB + NumberFields + [\"MonthlyLoanPayment\", \"LoanApproved\"]].head(10000)\n",
    "X = df_train.drop([\"LoanApproved\"], axis=1)\n",
    "\n",
    "# to standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To apply K-Means clustering, for two clusters only, approve/reject\n",
    "best_score = -1\n",
    "best_labels = None\n",
    "best_model = None\n",
    "b = pd.DataFrame()\n",
    "# random_state = 58 # 58 is best for full dataset, 48 is best for first half dataset\n",
    "for r in range(40,70):\n",
    "    kmeans_model = KMeans(n_clusters=2, init='k-means++', random_state=r)\n",
    "    labels = kmeans_model.fit_predict(X_scaled)\n",
    "    # score = silhouette_score(X_scaled, labels)\n",
    "    b[\"LoanApprovedCompare\"] = df_train[\"LoanApproved\"] == labels.astype('bool')\n",
    "    score = b[\"LoanApprovedCompare\"].value_counts()[True] / b[\"LoanApprovedCompare\"].value_counts()[False]\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_labels = labels\n",
    "        best_model = kmeans_model\n",
    "        print(f\"best random_state={r} -> score={score}\")\n",
    "    else:\n",
    "        print(f\"random_state={r} -> score={score}\")\n",
    "\n",
    "# to save the trained model\n",
    "dump(best_model, 'kmeans_model.joblib')\n",
    "\n",
    "# To add cluster labels to the original DataFrame\n",
    "C = X\n",
    "C['LoanApproved'] = df_train[\"LoanApproved\"]\n",
    "C['LoanApprovedAI'] = best_labels.astype('bool')\n",
    "C[\"LoanApprovedCompare\"] = C[\"LoanApproved\"] == C[\"LoanApprovedAI\"]\n",
    "\n",
    "C[\"LoanApprovedCompare\"].value_counts()[True] / C[\"LoanApprovedCompare\"].value_counts()[False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to re-use the model\n",
    "\n",
    "# to load the model from file\n",
    "new_model = load('kmeans_model.joblib')\n",
    "# to predict the result\n",
    "new_labels = new_model.predict(X_scaled)\n",
    "\n",
    "C = X\n",
    "C['LoanApproved'] = df_train[\"LoanApproved\"]\n",
    "C['LoanApprovedAINew'] = new_labels.astype('bool')\n",
    "C['LoanApprovedAI'] = best_labels.astype('bool')\n",
    "C[\"LoanApprovedCompare\"] = C[\"LoanApproved\"] == C[\"LoanApprovedAI\"]\n",
    "C[\"LoanApprovedAICompare\"] = C[\"LoanApprovedAI\"] == C[\"LoanApprovedAINew\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logic before change to Loan Approved Seed\n",
    "# to use unsupervised Gaussian Mixture method to train the model\n",
    "\n",
    "# to construct training data\n",
    "df_train = df[FeatureFieldNH + FeatureFieldOH + FeatureFieldB + NumberFields + [\"LoanAmount\", \"LoanDuration\", \"LoanApproved\", \"CreditScore\", \"RiskScore\"]].head(20000)\n",
    "\n",
    "# to derive X for training\n",
    "# exclude Outliers records, \n",
    "# removed the real LoanApproved indicator and CreditScore, RiskScore\n",
    "X = df_train.drop([\"LoanApproved\", \"CreditScore\", \"RiskScore\"], axis=1)\n",
    "\n",
    "# to standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# To apply GaussianMixture clustering, for two clusters only, approve/reject\n",
    "gmm = None\n",
    "best_score = -1\n",
    "best_labels = None\n",
    "best_model = None\n",
    "label_swap_indicator = False\n",
    "for r in range(40,60):\n",
    "    # to predict the value and train the model\n",
    "    gmm = GaussianMixture(n_components=2, init_params=\"random\", random_state=r)\n",
    "    labels = gmm.fit_predict(X_scaled)\n",
    "\n",
    "    # to evaluate the picking of cluster with two assumptions\n",
    "    # 1. the False is more than True, ie. Approve is less than Reject\n",
    "    # 2. the gap between False and True, bigger is better, ie. lesser Approve is better\n",
    "    b = pd.DataFrame()\n",
    "    b[\"LoanApprovedAI\"] = labels.astype('bool')\n",
    "    t = b[\"LoanApprovedAI\"].value_counts()[True]\n",
    "    f = b[\"LoanApprovedAI\"].value_counts()[False]\n",
    "    score = abs(t - f)/(t+f)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = gmm\n",
    "        if (t < f): # Approve is less than Reject\n",
    "            best_labels = b[\"LoanApprovedAI\"]\n",
    "            label_swap_indicator = False\n",
    "            print(f\"best random_state={r} -> score={score}, (t={t}/f={f})\")\n",
    "        else:\n",
    "            label_swap_indicator = True\n",
    "            print(f\"best random_state={r} -> score={score}, (f={f}/t={t})\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"random_state={r} -> score={score}/({t}/{f})\")\n",
    "\n",
    "# Predict the component labels for each data point\n",
    "\n",
    "# Print the means and covariances of the components\n",
    "print(\"Means:\", gmm.means_)\n",
    "print(\"Covariances:\", gmm.covariances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic before remove score calculation\n",
    "\n",
    "\n",
    "# to use unsupervised Gaussian Mixture method to train the model\n",
    "\n",
    "# to clone Y from training data, Y is used for result evaluation later\n",
    "Y = df_train.copy(deep=True)\n",
    "# to exclude Outlier data\n",
    "# Y = Y[Y[\"Outlier\"] == False]\n",
    "\n",
    "# to derive X for training\n",
    "X = Y.copy(deep=True)\n",
    "\n",
    "# to remove the manual label LoanApproved indicator and CreditScore, RiskScore, it may affect the training\n",
    "drop_fields = [\"LoanApproved\", \"CreditScore\", \"RiskScore\"]\n",
    "# to remove fields that are used to calculate other field. it may be redundant for training.\n",
    "drop_fields = drop_fields + [\"AnnualIncome\", \"TotalAssets\", \"TotalLiabilities\", \"LoanAmount\", ]\n",
    "drop_fields = drop_fields + [\"SavingsAccountBalance\", \"CheckingAccountBalance\", ]\n",
    "# drop_fields = drop_fields + [\"MonthlyIncome\", \"MonthlyDebtPayments\", \"MonthlyLoanPayment\", ]\n",
    "drop_fields = drop_fields + [\"Outlier\"]\n",
    "X = X.drop(drop_fields, axis=1)\n",
    "\n",
    "# to standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index) # to align the index\n",
    "\n",
    "# to train the model and predict the cluster\n",
    "best_model = None\n",
    "best_labels = None\n",
    "for e in range(1, 2):\n",
    "    # to calc the Seed Record that is approved for sure. It is used for training to identify which cluster is marked as approved.\n",
    "    LoanApprovedSeed = X.nlargest(64, \"NetWorth\").nlargest(16, \"MonthlyIncome\").nsmallest(4, \"MonthlyDebtPayments\").nsmallest(1, \"MonthlyLoanPayment\")\n",
    "\n",
    "    best_score = -1\n",
    "    for r in range(48,49):\n",
    "        # To use GaussianMixture for clustering, approve/reject\n",
    "        gmm = GaussianMixture(n_components=4, init_params=\"random\", random_state=r)\n",
    "\n",
    "        # to standardize the labels\n",
    "        labels = gmm.fit_predict(X_scaled)\n",
    "        b = pd.DataFrame({'LoanApprovedAIl' + str(e): labels}, index=X_scaled.index)\n",
    "        # to mark AI Loan Approved indicator as True if the label is same as the label of the seed record\n",
    "        b[\"LoanApprovedAI\" + str(e)] = b[\"LoanApprovedAIl\" + str(e)] == b.iat[LoanApprovedSeed.index[0], 0]\n",
    "\n",
    "        # to evaluate the picking of cluster\n",
    "        t = b[\"LoanApprovedAI\" + str(e)].value_counts()[True]\n",
    "        f = b[\"LoanApprovedAI\" + str(e)].value_counts()[False]\n",
    "        score = abs(t - f)/(t + f) # Balance Ratio, assume the gap between False and True, bigger is better, ie. lesser Approve is better\n",
    "        score = -abs(t - f)/(t + f) # Negative Balance Ratio, assume the gap between False and True, smaller is better, ie. Approve and Reject is similar\n",
    "        score = min(t, f) / max(t, f) # Class Balance Measure, assume Approve and Reject is similar\n",
    "        score = 1 - (t/(t + f))**2 - (f/(t + f))**2 # Gini Coefficient, assume Approve and Reject is similar\n",
    "        if score > best_score and t < f: \n",
    "            best_model = gmm\n",
    "            best_labels = b\n",
    "            best_score = score\n",
    "            print(f\"best epoch={e}, random_state={r}, Score={score}, True={t}, False={f}, SeedIndex={LoanApprovedSeed.index[0]}, SeedLabel={b.iat[LoanApprovedSeed.index[0], 0]}\")\n",
    "        else:\n",
    "            print(f\"epoch={e}, random_state={r}, Score={score}, True={t}, False={f}, SeedIndex={LoanApprovedSeed.index[0]}, SeedLabel={b.iat[LoanApprovedSeed.index[0], 0]}\")\n",
    "\n",
    "        b.value_counts()\n",
    "\n",
    "    Y[\"LoanApprovedAI\" + str(e)] = best_labels[\"LoanApprovedAI\" + str(e)]\n",
    "    Y[\"LoanApprovedAIl\" + str(e)] = best_labels[\"LoanApprovedAIl\" + str(e)]\n",
    "\n",
    "# Predict the component labels for each data point\n",
    "\n",
    "# Print the means and covariances of the components\n",
    "# print(\"Means:\", gmm.means_)\n",
    "# print(\"Covariances:\", gmm.covariances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logic to use repeat prediction for same set of data. result is fixed and no improvement.\n",
    "\n",
    "# to use unsupervised Gaussian Mixture method to train the model\n",
    "\n",
    "# to clone Y from training data, Y is used for result evaluation later\n",
    "Y = df_train.copy(deep=True).head(20000)\n",
    "Y[\"LoanApprovedAI\"] = False\n",
    "\n",
    "# to exclude Outlier data\n",
    "Y = Y[Y[\"Outlier\"] == False]\n",
    "\n",
    "# to derive X for training\n",
    "X = Y.copy(deep=True)\n",
    "\n",
    "# to remove the manual label LoanApproved indicator and CreditScore, RiskScore, it may affect the training\n",
    "drop_fields = [\"LoanApproved\", \"CreditScore\", \"RiskScore\"]\n",
    "# to remove fields that are used to calculate other field. it may be redundant for training.\n",
    "drop_fields = drop_fields + [\"AnnualIncome\", \"TotalAssets\", \"TotalLiabilities\", \"LoanAmount\", ]\n",
    "drop_fields = drop_fields + [\"SavingsAccountBalance\", \"CheckingAccountBalance\", ]\n",
    "# drop_fields = drop_fields + [\"MonthlyIncome\", \"MonthlyDebtPayments\", \"MonthlyLoanPayment\", ]\n",
    "drop_fields = drop_fields + [\"Outlier\"]\n",
    "X = X.drop(drop_fields, axis=1)\n",
    "\n",
    "# to train the model and predict the cluster\n",
    "# to define hyper-parameter\n",
    "hp_r = 48 # random_state\n",
    "hp_c = 6 # number of cluster for labeling\n",
    "hp_e = 5 # epoch for training\n",
    "hp_s = 0.2 # evaluation score\n",
    "\n",
    "# to standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index) # to align the index\n",
    "\n",
    "# To use GaussianMixture model for clustering, approve/reject\n",
    "gmm = GaussianMixture(n_components=hp_c, init_params=\"random\", random_state=hp_r)\n",
    "    \n",
    "best_model = None\n",
    "best_labels = None\n",
    "for e in range(1, hp_e + 1):\n",
    "    # to prepare X scaled of the epoch\n",
    "    # a = Y[Y[\"LoanApprovedAI\"] == False].index\n",
    "    Xe_scaled = X_scaled[X_scaled.index.isin(Y[Y[\"LoanApprovedAI\"] == False].index)]\n",
    "\n",
    "    # to calc the Seed Record that is approved for sure. It is used to identify which cluster is marked as approved during un-supervised training, semi-un-supervised\n",
    "    LoanApprovedSeed = Y[Y[\"LoanApprovedAI\"] == False].nlargest(64, \"NetWorth\").nlargest(16, \"MonthlyIncome\").nsmallest(4, \"MonthlyDebtPayments\").nsmallest(1, \"MonthlyLoanPayment\")\n",
    "\n",
    "    # to standardize the labels\n",
    "    labels = gmm.fit_predict(Xe_scaled)\n",
    "    b = pd.DataFrame({\"LoanApprovedAIl\" + str(e): labels}, index=Xe_scaled.index)\n",
    "    b[\"LoanApprovedAI\" + str(e)] = b[\"LoanApprovedAIl\" + str(e)] == b.loc[LoanApprovedSeed.index[0]][0]\n",
    "\n",
    "    # to evaluate the picking of cluster\n",
    "    t = b[\"LoanApprovedAI\" + str(e)].value_counts()[True]\n",
    "    f = b[\"LoanApprovedAI\" + str(e)].value_counts()[False]\n",
    "    score = -abs(t - f)/(t + f) # Negative Balance Ratio, assume the gap between False and True, smaller is better, ie. Approve and Reject is similar\n",
    "    score = 1 - (t/(t + f))**2 - (f/(t + f))**2 # Gini Coefficient, assume Approve and Reject is similar\n",
    "    score = abs(t - f)/(t + f) # Balance Ratio, assume the gap between False and True, bigger is better, ie. lesser Approve is better\n",
    "    score = min(t, f) / max(t, f) # Class Balance Measure, assume Approve and Reject is similar\n",
    "    if score > hp_s: \n",
    "        print(f\"skip, epoch={e}, random_state={hp_r}, Score={score}, True={t}, False={f}\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"epoch={e}, random_state={hp_r}, Score={score}, True={t}, False={f}\")\n",
    "        \n",
    "    # to keep the label\n",
    "    Y[\"LoanApprovedAIl\" + str(e)] = b[\"LoanApprovedAIl\" + str(e)]\n",
    "    # to mark LoanApprovedAI of current epoch as True if the label is same as the label of the seed record\n",
    "    Y[\"LoanApprovedAI\" + str(e)] = b[\"LoanApprovedAI\" + str(e)]\n",
    "\n",
    "    # to mark the overall LoanApprovedAI as True if any of epoch mark the it as Approved\n",
    "    col_approved =[]\n",
    "    for i in range(1, e + 1):\n",
    "        col_approved.append(\"LoanApprovedAI\" + str(i))\n",
    "    Y[\"LoanApprovedAI\"] = Y[col_approved].any(axis=1)\n",
    "\n",
    "    print(f\"epoch={e}, random_state={hp_r}, SeedIndex={LoanApprovedSeed.index[0]}, SeedLabel={b.loc[LoanApprovedSeed.index[0]][0]}\")\n",
    "    b.value_counts()\n",
    "    df_group = Y.groupby([\"LoanApprovedAI\", \"LoanApproved\"]).agg({'MonthlyLoanPayment': ['sum', 'count']})\n",
    "    formatted_sum = df_group.applymap(lambda x: f\"{x:,.2f}\")\n",
    "    print(formatted_sum)\n",
    "\n",
    "# Predict the component labels for each data point\n",
    "\n",
    "# Print the means and covariances of the components\n",
    "# print(\"Means:\", gmm.means_)\n",
    "# print(\"Covariances:\", gmm.covariances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to draw static diagram\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(eval_result['Clusters'], eval_result['Random'], eval_result['Score'], \n",
    "           s=eval_result['Accuracy']*1000,  # Scale Accuracy to suitable dot size\n",
    "           alpha=0.7, edgecolors='black')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Clusters')\n",
    "ax.set_ylabel('Random')\n",
    "ax.set_zlabel('Score')\n",
    "ax.set_title('3D Scatter Plot of Clusters, Random, and Score')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories\n",
    "categories = ['TT', 'FF', 'TF', 'FT']\n",
    "N = len(categories)\n",
    "\n",
    "# Angles\n",
    "angles = np.linspace(0, 2*np.pi, N, endpoint=False)\n",
    "\n",
    "# Create radar chart\n",
    "fig = go.Figure()\n",
    "for i, cluster in enumerate(data['Clusters'].unique()):\n",
    "    values = data[data['Clusters'] == cluster][['TT', 'FF', 'TF', 'FT']].mean().values\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=values,\n",
    "        theta=categories,\n",
    "        name=f'Cluster {cluster}',\n",
    "        line=dict(color=f'rgb({i*50}, {i*20}, {i*100})')\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Radar Chart',\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, data[['TT', 'FF', 'TF', 'FT']].max().max()]\n",
    "        )\n",
    "    ),\n",
    "    showlegend=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create radar chart\n",
    "categories = ['TT', 'FF', 'TF', 'FT']\n",
    "N = len(categories)\n",
    "\n",
    "# Plot radar chart\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, cluster in enumerate(data['Clusters'].unique()):\n",
    "    values = data[data['Clusters'] == cluster][['TT', 'FF', 'TF', 'FT']].mean().values\n",
    "    angles = np.linspace(0, 2*np.pi, N, endpoint=False)\n",
    "    plt.polar(angles, values, 'o-', linewidth=2, label=cluster)\n",
    "\n",
    "plt.thetagrids(angles * 180/np.pi, categories)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "conf_mat = data[['TT', 'FF', 'TF', 'FT']]\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt data for plotting\n",
    "data_melt = data.melt(id_vars=['Clusters', 'Random'], value_vars=['TT', 'FF', 'TF', 'FT'])\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Clusters', y='Random', hue='Clusters', data=data_melt)\n",
    "plt.title('TT, FF, TF, FT Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to prepare evaluation records for visualization analysis\n",
    "C = pd.DataFrame()\n",
    "C[\"LoanApproved\"] = Y[\"LoanApproved\"]\n",
    "C[\"LoanApprovedAI\"] = b[\"LoanApprovedAI\"]\n",
    "Y[\"LoanApprovedCompare\"] = C[\"LoanApproved\"] == C[\"LoanApprovedAI\"]\n",
    "\n",
    "accuracy = C[\"LoanApprovedCompare\"].value_counts()[True]/(C[\"LoanApprovedCompare\"].value_counts()[True] + C[\"LoanApprovedCompare\"].value_counts()[False])\n",
    "print(f\"Accuracy={accuracy}\")\n",
    "\n",
    "la_tf = C.groupby([\"LoanApprovedAI\", \"LoanApproved\"]).size()\n",
    "eval_result = pd.concat([eval_result, pd.Series({\"Clusters\": c, \"Random\": r, \"Score\": score, \"Accuracy\": accuracy, \"TT\": la_tf.loc[(True,True)], \"FF\": la_tf.loc[(False,False)], \"TF\": la_tf.loc[(True,False)], \"FT\": la_tf.loc[(False,True)]}).to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot matrix\n",
    "sns.pairplot(data[['TT', 'FF', 'TF', 'FT']].head(1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to draw live diagram to show the most accuracy data\n",
    "max_acc_idx = eval_result['Accuracy'].idxmax()\n",
    "max_score_idx = eval_result['Score'].idxmax()\n",
    "\n",
    "# 3D scatter plot\n",
    "fig = go.Figure(data=[\n",
    "        go.Scatter3d(\n",
    "            x=eval_result['Clusters'],\n",
    "            y=eval_result['Random'],\n",
    "            z=eval_result['Score'],\n",
    "            mode='markers',\n",
    "            marker=dict(size=eval_result['Accuracy']*50, color='blue'),\n",
    "            hoverinfo='text',\n",
    "            hovertext=[f\"Accuracy: {acc:.2f}%\" for acc in eval_result['Accuracy']*100]),\n",
    "        go.Scatter3d(\n",
    "            x=[eval_result.loc[max_acc_idx, 'Clusters']],\n",
    "            y=[eval_result.loc[max_acc_idx, 'Random']],\n",
    "            z=[eval_result.loc[max_acc_idx, 'Score']],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=[eval_result.loc[max_acc_idx, 'Accuracy']*50], \n",
    "                color='orange', \n",
    "                symbol='circle',\n",
    "                line=dict(width=1)\n",
    "            ),\n",
    "            hoverinfo='text',\n",
    "            hovertext=[f\"Max Accuracy: {eval_result.loc[max_acc_idx, 'Accuracy']*100:.2f}%\"]),\n",
    "        go.Scatter3d(\n",
    "            x=[eval_result.loc[max_score_idx, 'Clusters']],\n",
    "            y=[eval_result.loc[max_score_idx, 'Random']],\n",
    "            z=[eval_result.loc[max_score_idx, 'Score']],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=[eval_result.loc[max_score_idx, 'Accuracy']*50], \n",
    "                color='green', \n",
    "                symbol='circle',\n",
    "                line=dict(width=1)\n",
    "            ),\n",
    "            hoverinfo='text',\n",
    "            hovertext=[f\"Accuracy of Max Score: {eval_result.loc[max_score_idx, 'Accuracy']*100:.2f}%\"])\n",
    "    ])\n",
    "\n",
    "# Set labels and title\n",
    "fig.update_layout(\n",
    "    title='Clusters, Random, Score and Accuracy',\n",
    "    scene=dict(\n",
    "        xaxis_title='Clusters',\n",
    "        xaxis=dict(tickformat=\"d\", dtick=1),\n",
    "        yaxis_title='Random',\n",
    "        yaxis=dict(tickformat=\"d\", dtick=1),\n",
    "        zaxis_title='Score'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show interactive plot\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To evaluate the result add cluster labels to the original DataFrame\n",
    "\n",
    "C1 = X1.copy(deep=True)\n",
    "C1['LoanApproved'] = C[\"LoanApproved\"]\n",
    "C1['LoanApprovedAI'] = best_labels1[\"LoanApprovedAI\"]\n",
    "C1[\"LoanApprovedCompare\"] = C1[\"LoanApproved\"] == C1[\"LoanApprovedAI\"]\n",
    "\n",
    "C1[\"LoanApprovedCompare\"].value_counts()\n",
    "C1[\"LoanApprovedCompare\"].value_counts()[True]/(C1[\"LoanApprovedCompare\"].value_counts()[True] + C1[\"LoanApprovedCompare\"].value_counts()[False])\n",
    "\n",
    "df_group = C1.groupby([\"LoanApprovedCompare\", \"LoanApprovedAI\", \"LoanApproved\"]).agg({'MonthlyLoanPayment': ['sum', 'count']})\n",
    "formatted_sum = df_group.applymap(lambda x: f\"{x:,.2f}\")\n",
    "print(formatted_sum)\n",
    "\n",
    "C1.iloc[LoanApprovedSeed.index[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find out the relation between features and labels\n",
    "\n",
    "# Calculate silhouette score\n",
    "# silhouette_avg = silhouette_score(C, best_labels)\n",
    "# print(\"Silhouette score:\", silhouette_avg)\n",
    "\n",
    "# Calculate correlation coefficients\n",
    "# correlations = C.corrwith(pd.Series(best_labels))\n",
    "# print(\"Correlations:\")\n",
    "# print(correlations)\n",
    "\n",
    "# Create box plots\n",
    "# sns.boxplot(x=labels, y='Age', data=C)\n",
    "# plt.title('Age 1 vs. Cluster')\n",
    "# plt.show()\n",
    "\n",
    "# Create scatter plots\n",
    "# sns.scatterplot(x='TotalAssets', y='EmploymentStatus_Employed', hue=C['LoanApproved'], data=C)\n",
    "# plt.title('EmploymentStatus_Employed 1 vs. TotalAssets 2 by Cluster')\n",
    "# plt.show()\n",
    "\n",
    "# sns.pairplot(df_train[[\"MonthlyLoanPayment\", \"TotalAssets\", \"TotalLiabilities\", \"MonthlyDebtPayments\", \"AnnualIncome\"] + ['LoanApproved']], hue='LoanApproved', diag_kind='kde', palette='viridis', markers=['o', 'o', 'o'])\n",
    "# plt.show()\n",
    "\n",
    "# sns.factorplot()\n",
    "\n",
    "# to fine out what are the fields that may affect the LoadApproved\n",
    "# to find out what are the fields that may affect CreditScore\n",
    "# to find out what are the fields that may affect RiskScore\n",
    "# to find out what are the fields that may affect the BaseInterestRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to analysis C DataFrame, to find out what is pattern for discrepancy between the real result and AI result.\n",
    "CorrFields = [\n",
    "    \"TotalDebtToIncomeRatio\", \"BankruptcyHistory\", \"NetWorth\", \"PreviousLoanDefaults\", \\\n",
    "    # \"LoanAmount\", \"TotalAssets\", \"TotalLiabilities\", \"MonthlyDebtPayments\", \"AnnualIncome\", \\\n",
    "              ]\n",
    "df_false = C[C[\"LoanApprovedCompare\"] == False][C[\"LoanApprovedAI\"] == True]\n",
    "\n",
    "# to show all fields correlation\n",
    "correlation_matrix = df_false[CorrFields].corr()\n",
    "\n",
    "threshold = 0.01\n",
    "mask = abs(correlation_matrix) > threshold\n",
    "correlation_matrix_filtered = correlation_matrix.where(mask, np.nan)\n",
    "\n",
    "fz = len(CorrFields) * 2\n",
    "plt.figure(figsize=(fz, fz))\n",
    "sns.heatmap(correlation_matrix_filtered, annot=True, cmap='viridis', linewidths=0.5)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('AI Approved by Manual Rejected Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "new_scaler = load('credit-risk-scaler.joblib')\n",
    "try:\n",
    "    check_is_fitted(new_scaler)  # This will raise an error if not fitted\n",
    "except :\n",
    "    print(\"Scaler is not fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Processing\n",
    "\n",
    "# object fields using factorize encoding\n",
    "Best Score=0.45213374731665806, cluster=2, random_state=42, True=1658, False=18342, SeedIndex=9567, SeedLabel=0\n",
    "Clusters\tRandom\tScore\tAT\tAF\tAccuracy\tWeighted_Score\tTT\tFF\tTF\tFT\n",
    "0\t2.0\t42.0\t0.452134\t1658.0\t18342.0\t0.7225\t0.6078\t444.0\t14006.0\t1214.0\t4336.0\n",
    "\n",
    "# object fields using one-hot encoding\n",
    "Best Score=0.03861680396615764, cluster=2, random_state=42, True=16773, False=3227, SeedIndex=9567, SeedLabel=0\n",
    "Clusters\tRandom\tScore\tAT\tAF\tAccuracy\tWeighted_Score\tTT\tFF\tTF\tFT\n",
    "0\t2.0\t42.0\t0.038617\t16773.0\t3227.0\t0.31475\t0.61325\t3924.0\t2371.0\t12849.0\t856.0\n",
    "\n",
    "# number fields using bin + one-hot encoding\n",
    "Best Score=0.04699579069683076, cluster=2, random_state=42, True=15892, False=4108, SeedIndex=9567, SeedLabel=0\n",
    "Clusters\tRandom\tScore\tAT\tAF\tAccuracy\tWeighted_Score\tTT\tFF\tTF\tFT\n",
    "0\t2.0\t42.0\t0.046996\t15892.0\t4108.0\t0.3261\t0.607345\t3597.0\t2925.0\t12295.0\t1183.0\n",
    "\n",
    "# keep SavingsAccountBalance, CheckingAccountBalance\n",
    "Best Score=0.03942458468960572, cluster=2, random_state=42, True=15541, False=4459, SeedIndex=9567, SeedLabel=0\n",
    "Clusters\tRandom\tScore\tAT\tAF\tAccuracy\tWeighted_Score\tTT\tFF\tTF\tFT\n",
    "0\t2.0\t42.0\t0.039425\t15541.0\t4459.0\t0.33935\t0.60892\t3554.0\t3233.0\t11987.0\t1226.0\n",
    "\n",
    "# removed calculated field\n",
    "Best Score=0.18485707762202727, cluster=2, random_state=42, True=2103, False=17897, SeedIndex=9567, SeedLabel=0\n",
    "Clusters\tRandom\tScore\tAT\tAF\tAccuracy\tWeighted_Score\tTT\tFF\tTF\tFT\n",
    "0\t2.0\t42.0\t0.184857\t2103.0\t17897.0\t0.71775\t0.611225\t619.0\t13736.0\t1484.0\t4161.0\n",
    "# removed original fields\n",
    "Best Score=0.22915200000000002, cluster=6, random_state=42, True=2640, False=17360, SeedIndex=9567, SeedLabel=2\n",
    "Accuracy=0.6755\n",
    "Clusters        6.000000\n",
    "Random         42.000000\n",
    "Score           0.229152\n",
    "AT           2640.000000\n",
    "AF          17360.000000\n",
    "Accuracy        0.675500\n",
    "TT            465.000000\n",
    "FF          13045.000000\n",
    "TF           2175.000000\n",
    "FT           4315.000000\n",
    "\n",
    "# to use kmean++\n",
    "Best Score=0.20285659500000008, cluster=6, random_state=42, True=2291, False=17709, SeedIndex=9567, SeedLabel=4\n",
    "Accuracy=0.70525\n",
    "Clusters        6.000000\n",
    "Random         42.000000\n",
    "Score           0.202857\n",
    "AT           2291.000000\n",
    "AF          17709.000000\n",
    "Accuracy        0.705250\n",
    "TT            588.000000\n",
    "FF          13517.000000\n",
    "TF           1703.000000\n",
    "FT           4192.000000\n",
    "\n",
    "# to use silhouette_score to evaluate\n",
    "Best Score=-0.00399347717175795, cluster=6, random_state=42, True=2640, False=17360, SeedIndex=9567, SeedLabel=2\n",
    "Accuracy=0.6755\n",
    "Clusters        6.000000\n",
    "Random         42.000000\n",
    "Score          -0.003993\n",
    "AT           2640.000000\n",
    "AF          17360.000000\n",
    "Accuracy        0.675500\n",
    "TT            465.000000\n",
    "FF          13045.000000\n",
    "TF           2175.000000\n",
    "FT           4315.000000\n",
    "\n",
    "## final best result with all above tuning\n",
    "Best Score=0.45614964715122097, cluster=2, random_state=43, True=1793, False=18207, SeedIndex=9567, SeedLabel=1\n",
    "Accuracy=0.74435\n",
    "Clusters        2.00000\n",
    "Random         43.00000\n",
    "Score           0.45615\n",
    "AT           1793.00000\n",
    "AF          18207.00000\n",
    "Accuracy        0.74435\n",
    "TT            730.00000\n",
    "FF          14157.00000\n",
    "TF           1063.00000\n",
    "FT           4050.00000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Score=0.499654155, cluster=2, random_state=42, True=10263, False=9737, SeedIndex=9567, SeedLabel=1\n",
    "Clusters\tRandom\tScore\tAT\tAF\tAccuracy\tWeighted_Score\tTT\tFF\tTF\tFT\n",
    "0\t2.0\t42.0\t0.499654\t10263.0\t9737.0\t0.68585\t0.69887\t4380.0\t9337.0\t5883.0\t400.0\n",
    "\n",
    "\n",
    "Best Score=0.4993043549999999, cluster=2, random_state=42, True=10373, False=9627, SeedIndex=9567, SeedLabel=1\n",
    "Clusters\tRandom\tScore\tAT\tAF\tAccuracy\tWeighted_Score\tTT\tFF\tTF\tFT\n",
    "0\t2.0\t42.0\t0.499304\t10373.0\t9627.0\t0.68585\t0.700245\t4435.0\t9282.0\t5938.0\t345.0\n",
    "\n",
    "Best Score=0.48019949999999995, cluster=2, random_state=42, True=8010, False=11990, SeedIndex=9567, SeedLabel=1\n",
    "Clusters\tRandom\tScore\tAT\tAF\tAccuracy\tWeighted_Score\tTT\tFF\tTF\tFT\n",
    "0\t2.0\t42.0\t0.480199\t8010.0\t11990.0\t0.5992\t0.631715\t2387.0\t9597.0\t5623.0\t2393.0\n",
    "\n",
    "\n",
    "Best Score=0.49982328000000004, cluster=2, random_state=42, True=10188, False=9812, SeedIndex=9567, SeedLabel=0\n",
    "Clusters\tRandom\tScore\tAT\tAF\tAccuracy\tWeighted_Score\tTT\tFF\tTF\tFT\n",
    "0\t2.0\t42.0\t0.499823\t10188.0\t9812.0\t0.6571\t0.684995\t4055.0\t9087.0\t6133.0\t725.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT</th>\n",
       "      <th>FF</th>\n",
       "      <th>TF</th>\n",
       "      <th>FT</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>682</td>\n",
       "      <td>13636</td>\n",
       "      <td>1584</td>\n",
       "      <td>4098</td>\n",
       "      <td>Factorize Encoding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484</td>\n",
       "      <td>13601</td>\n",
       "      <td>1619</td>\n",
       "      <td>4296</td>\n",
       "      <td>One-Hot Encoding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>15049</td>\n",
       "      <td>171</td>\n",
       "      <td>4692</td>\n",
       "      <td>Bin + One-Hot Encoding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386</td>\n",
       "      <td>13957</td>\n",
       "      <td>1263</td>\n",
       "      <td>4394</td>\n",
       "      <td>Remove A/C Balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367</td>\n",
       "      <td>14067</td>\n",
       "      <td>1153</td>\n",
       "      <td>4413</td>\n",
       "      <td>Remove DebtToIncomeRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>465</td>\n",
       "      <td>13045</td>\n",
       "      <td>2175</td>\n",
       "      <td>4315</td>\n",
       "      <td>Remove Original Fields to calc DebtToIncomeRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>588</td>\n",
       "      <td>13517</td>\n",
       "      <td>1703</td>\n",
       "      <td>4192</td>\n",
       "      <td>Use KMeans ++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>465</td>\n",
       "      <td>13045</td>\n",
       "      <td>2175</td>\n",
       "      <td>4315</td>\n",
       "      <td>Use SilHouette Score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>730</td>\n",
       "      <td>14157</td>\n",
       "      <td>1063</td>\n",
       "      <td>4050</td>\n",
       "      <td>Use 2 Clusters and Random State 43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TT     FF    TF    FT                                       Description\n",
       "0  682  13636  1584  4098                                Factorize Encoding\n",
       "1  484  13601  1619  4296                                  One-Hot Encoding\n",
       "2   88  15049   171  4692                            Bin + One-Hot Encoding\n",
       "3  386  13957  1263  4394                                Remove A/C Balance\n",
       "4  367  14067  1153  4413                          Remove DebtToIncomeRatio\n",
       "5  465  13045  2175  4315  Remove Original Fields to calc DebtToIncomeRatio\n",
       "6  588  13517  1703  4192                                     Use KMeans ++\n",
       "7  465  13045  2175  4315                              Use SilHouette Score\n",
       "8  730  14157  1063  4050                Use 2 Clusters and Random State 43"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TT</th>\n",
       "      <th>FF</th>\n",
       "      <th>TF</th>\n",
       "      <th>FT</th>\n",
       "      <th>Description</th>\n",
       "      <th>WeightedScore</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>682</td>\n",
       "      <td>13636</td>\n",
       "      <td>1584</td>\n",
       "      <td>4098</td>\n",
       "      <td>Factorize Encoding</td>\n",
       "      <td>0.612430</td>\n",
       "      <td>0.71590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484</td>\n",
       "      <td>13601</td>\n",
       "      <td>1619</td>\n",
       "      <td>4296</td>\n",
       "      <td>One-Hot Encoding</td>\n",
       "      <td>0.605150</td>\n",
       "      <td>0.70425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>15049</td>\n",
       "      <td>171</td>\n",
       "      <td>4692</td>\n",
       "      <td>Bin + One-Hot Encoding</td>\n",
       "      <td>0.605770</td>\n",
       "      <td>0.75685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386</td>\n",
       "      <td>13957</td>\n",
       "      <td>1263</td>\n",
       "      <td>4394</td>\n",
       "      <td>Remove A/C Balance</td>\n",
       "      <td>0.605280</td>\n",
       "      <td>0.71715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367</td>\n",
       "      <td>14067</td>\n",
       "      <td>1153</td>\n",
       "      <td>4413</td>\n",
       "      <td>Remove DebtToIncomeRatio</td>\n",
       "      <td>0.605715</td>\n",
       "      <td>0.72170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>465</td>\n",
       "      <td>13045</td>\n",
       "      <td>2175</td>\n",
       "      <td>4315</td>\n",
       "      <td>Remove Original Fields to calc DebtToIncomeRatio</td>\n",
       "      <td>0.598925</td>\n",
       "      <td>0.67550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>588</td>\n",
       "      <td>13517</td>\n",
       "      <td>1703</td>\n",
       "      <td>4192</td>\n",
       "      <td>Use KMeans ++</td>\n",
       "      <td>0.607950</td>\n",
       "      <td>0.70525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>465</td>\n",
       "      <td>13045</td>\n",
       "      <td>2175</td>\n",
       "      <td>4315</td>\n",
       "      <td>Use SilHouette Score</td>\n",
       "      <td>0.598925</td>\n",
       "      <td>0.67550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>730</td>\n",
       "      <td>14157</td>\n",
       "      <td>1063</td>\n",
       "      <td>4050</td>\n",
       "      <td>Use 2 Clusters and Random State 43</td>\n",
       "      <td>0.619320</td>\n",
       "      <td>0.74435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TT     FF    TF    FT                                       Description  \\\n",
       "0  682  13636  1584  4098                                Factorize Encoding   \n",
       "1  484  13601  1619  4296                                  One-Hot Encoding   \n",
       "2   88  15049   171  4692                            Bin + One-Hot Encoding   \n",
       "3  386  13957  1263  4394                                Remove A/C Balance   \n",
       "4  367  14067  1153  4413                          Remove DebtToIncomeRatio   \n",
       "5  465  13045  2175  4315  Remove Original Fields to calc DebtToIncomeRatio   \n",
       "6  588  13517  1703  4192                                     Use KMeans ++   \n",
       "7  465  13045  2175  4315                              Use SilHouette Score   \n",
       "8  730  14157  1063  4050                Use 2 Clusters and Random State 43   \n",
       "\n",
       "   WeightedScore  Accuracy  \n",
       "0       0.612430   0.71590  \n",
       "1       0.605150   0.70425  \n",
       "2       0.605770   0.75685  \n",
       "3       0.605280   0.71715  \n",
       "4       0.605715   0.72170  \n",
       "5       0.598925   0.67550  \n",
       "6       0.607950   0.70525  \n",
       "7       0.598925   0.67550  \n",
       "8       0.619320   0.74435  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval_result = pd.DataFrame()\n",
    "j = [\n",
    "    {\"TT\": 682, \"FF\": 13636, \"TF\": 1584, \"FT\": 4098, \"Description\": \"Factorize Encoding\"},\n",
    "    {\"TT\": 484, \"FF\": 13601, \"TF\": 1619, \"FT\": 4296, \"Description\": \"One-Hot Encoding\"},\n",
    "    {\"TT\": 88,  \"FF\": 15049, \"TF\": 171,  \"FT\": 4692, \"Description\": \"Bin + One-Hot Encoding\"},\n",
    "    {\"TT\": 386, \"FF\": 13957, \"TF\": 1263, \"FT\": 4394, \"Description\": \"Remove A/C Balance\"},\n",
    "    {\"TT\": 367, \"FF\": 14067, \"TF\": 1153, \"FT\": 4413, \"Description\": \"Remove DebtToIncomeRatio\"},\n",
    "    {\"TT\": 465, \"FF\": 13045, \"TF\": 2175, \"FT\": 4315, \"Description\": \"Remove Original Fields to calc DebtToIncomeRatio\"},\n",
    "    {\"TT\": 588, \"FF\": 13517, \"TF\": 1703, \"FT\": 4192, \"Description\": \"Use KMeans ++\"},\n",
    "    {\"TT\": 465, \"FF\": 13045, \"TF\": 2175, \"FT\": 4315, \"Description\": \"Use SilHouette Score\"},\n",
    "    {\"TT\": 730, \"FF\": 14157, \"TF\": 1063, \"FT\": 4050, \"Description\": \"Use 2 Clusters and Random State 43\"},\n",
    "]\n",
    "eval_result = pd.DataFrame(j)\n",
    "eval_result\n",
    "\n",
    "# Custom weights\n",
    "W_TT = 1.0   # TT (True Positives), Actual Value is same as Predicted Value, both are True\n",
    "W_FF = 0.7   # FF (True Negatives), Actual Value is same as Predicted Value, both are False\n",
    "W_TF = 0.5   # TF (False Negatives), Actual Value is False, Predicted Value is True\n",
    "W_FT = 0.3   # FT (False Positives), Actual Value is True, Predicted Value is False\n",
    "\n",
    "for i in range(0,len(eval_result)):\n",
    "    TP = eval_result.loc[i][\"TT\"]  # True Positive (TT)\n",
    "    TN = eval_result.loc[i][\"FF\"]  # True Negative (FF)\n",
    "    FN = eval_result.loc[i][\"TF\"]  # False Negative (TF)\n",
    "    FP = eval_result.loc[i][\"FT\"]  # False Positive (FT)\n",
    "    total_outcomes = TP + TN + FN + FP\n",
    "    weighted_score = ((W_TT * TP) + (W_FF * TN) + (W_TF * FN) + (W_FT * FP)) / total_outcomes\n",
    "    accuracy = (TP + TN) / total_outcomes\n",
    "    eval_result.loc[i,\"WeightedScore\"] = weighted_score\n",
    "    eval_result.loc[i,\"Accuracy\"] = accuracy\n",
    "    \n",
    "eval_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoanApprovedAI  LoanApproved\n",
      "0               0               4\n",
      "                1               1\n",
      "1               0               1\n",
      "                1               4\n",
      "dtype: int64\n",
      "Weighted Score: 0.775\n",
      "Accuracy: 0.8\n",
      "Precision: 0.8\n",
      "Recall: 0.8\n",
      "F1 Score: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Sample true and predicted labels\n",
    "y_true = np.array([1, 1, 0, 0, 1, 1, 0, 0, 1, 0])  # True labels, Actual Value, \n",
    "y_pred = np.array([1, 1, 0, 1, 1, 0, 0, 0, 1, 0])  # Predicted labels, Predicted Value\n",
    "\n",
    "y=pd.DataFrame()\n",
    "y[\"LoanApproved\"] = y_true\n",
    "y[\"LoanApprovedAI\"] = y_pred\n",
    "# y[\"LoanApprovedCompare\"] = y[\"LoanApproved\"] == y[\"LoanApprovedAI\"]\n",
    "\n",
    "da_group = y.groupby([\"LoanApprovedAI\", \"LoanApproved\"]).size()\n",
    "print(da_group)\n",
    "\n",
    "# Custom weights\n",
    "W_TT = 1.0   # TT (True Positives), Actual Value is same as Predicted Value, both are True\n",
    "W_FF = 0.75  # FF (True Negatives), Actual Value is same as Predicted Value, both are False\n",
    "W_TF = 0.5   # TF (False Negatives), Actual Value is True, Predicted Value is False\n",
    "W_FT = 0.25  # FT (False Positives), Actual Value is False, Predicted Value is True\n",
    "\n",
    "# Confusion matrix to count TT, FF, TF, FT\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "TP = cm[1, 1]  # True Positive (TT)\n",
    "TN = cm[0, 0]  # True Negative (FF)\n",
    "FN = cm[1, 0]  # False Negative (TF)\n",
    "FP = cm[0, 1]  # False Positive (FT)\n",
    "\n",
    "# Total number of outcomes\n",
    "total_outcomes = len(y_true)\n",
    "\n",
    "# Custom weighted score\n",
    "weighted_score = ((W_TT * TP) + (W_FF * TN) + (W_TF * FN) + (W_FT * FP)) / total_outcomes\n",
    "\n",
    "# Basic accuracy\n",
    "accuracy = np.sum(y_true == y_pred) / total_outcomes\n",
    "\n",
    "# Precision, recall, and F1 score for comparison\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Weighted Score: {weighted_score}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to draw live diagram to show the most accuracy data\n",
    "max_acc_idx = eval_result['Weighted'].idxmax()\n",
    "max_score_idx = eval_result['Score'].idxmax()\n",
    "\n",
    "# 3D scatter plot\n",
    "fig = go.Figure(data=[\n",
    "        go.Scatter3d(\n",
    "            x=eval_result['Clusters'],\n",
    "            y=eval_result['Random'],\n",
    "            z=eval_result['Score'],\n",
    "            mode='markers',\n",
    "            marker=dict(size=eval_result['Weighted']*50, color='blue'),\n",
    "            hoverinfo='text',\n",
    "            hovertext=[f\"Weighted: {acc:.2f}%\" for acc in eval_result['Weighted']*100],\n",
    "            name=\"Score\",),\n",
    "        go.Scatter3d(\n",
    "            x=[eval_result.loc[max_acc_idx, 'Clusters']],\n",
    "            y=[eval_result.loc[max_acc_idx, 'Random']],\n",
    "            z=[eval_result.loc[max_acc_idx, 'Score']],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=[eval_result.loc[max_acc_idx, 'Weighted']*50], \n",
    "                color='orange', \n",
    "                symbol='circle',\n",
    "                line=dict(width=1)\n",
    "            ),\n",
    "            hoverinfo='text',\n",
    "            hovertext=[f\"Max Weighted: {eval_result.loc[max_acc_idx, 'Weighted']*100:.2f}%\"],\n",
    "            name=\"Max Weighted\",),\n",
    "        go.Scatter3d(\n",
    "            x=[eval_result.loc[max_score_idx, 'Clusters']],\n",
    "            y=[eval_result.loc[max_score_idx, 'Random']],\n",
    "            z=[eval_result.loc[max_score_idx, 'Score']],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=[eval_result.loc[max_score_idx, 'Weighted']*50], \n",
    "                color='green', \n",
    "                symbol='circle',\n",
    "                line=dict(width=1)\n",
    "            ),\n",
    "            hoverinfo='text',\n",
    "            hovertext=[f\"Max Weighted: {eval_result.loc[max_score_idx, 'Weighted']*100:.2f}%\"],\n",
    "            name=\"Max Score\",),\n",
    "    ])\n",
    "\n",
    "# Set labels and title\n",
    "fig.update_layout(\n",
    "    title='Clusters, Random, Score and Weighted',\n",
    "    scene=dict(\n",
    "        xaxis_title='Clusters',\n",
    "        xaxis=dict(tickformat=\"d\", dtick=1),\n",
    "        yaxis_title='Random',\n",
    "        yaxis=dict(tickformat=\"d\", dtick=1),\n",
    "        zaxis_title='Score'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show interactive plot\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlation_matrix = X.corr()\n",
    "plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='viridis', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(x=\"Age\", y=\"AnnualIncome\", data=X, hue=labels, palette='viridis')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Scatterplot of Cluster Categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \"BaseInterestRate\", \"InterestRate\", \"MonthlyLoanPayment\", could be Output fields. to be test in future.\n",
    "2. to do pairplot for all feature fields.\n",
    "3. to find out why outlier (IsolationForest) impact the accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
